# Amazon Simple Storage Service (S3)
Provides secure, durable, higly-scalabe **object store**.

## Useful Links
- [AWS - S3 FAQ](https://aws.amazon.com/s3/faqs/)
- [AWS - S3 Security Best Practices](https://docs.aws.amazon.com/AmazonS3/latest/dev/security-best-practices.html)
- [AWS - Best Practices Design Patterns: Optimizing Amazon S3 Performance](https://docs.aws.amazon.com/AmazonS3/latest/dev/optimizing-performance.html)

## General Notes
- Safe place to store your files
- Allows you to upload files, but is not suitable to install an OS or running a database
- **Object-based** storage (not blob storage)
- Data is spread across multiple devices and facilities (+ high availability and + disaster recovery)
- Files can be from 0 bytes to 5TB
- **Unlimited storage** (pay as you go)
- Files are stored in **Buckets** (similar to folder)
- S3 is an universal namespace, so **names must be unique globally**
- When you upload a file, you will receive a HTTP 200 code if it was successful
- Data consistency:
    - **Read after write consistency** for PUTs of **new objects**
    - **Eventual consistency for overwrite** PUTs and DELETEs (can take some time to propagate)
- S3 is **key-value based**, and objects consists of:
    - Key: the name of the object
    - Value: the actual data, made up of a sequence of bytes
    - Version id
    - Metadata: such as tags
    - Subresources: bucket-specific configuration, such as:
        - bucket policies, access control lists
        - CORS
        - Transfer acceleration
- Amazon guarantees **99.9% availability** and **99.999999999% durability** for S3 information (11x9s) 
- Storage Tiers
    - **S3**: store redudantly accross multiple facilities, and is designed to sustain the loss of 2 facilities concurrently
    - **S3 IA (Infrequently Accessed)**: for data that is accessed less frequently, but requires rapid access when needed. There is a **retrieval fee** for all s3 objects
    - **S3 One Zone IA**: same as IA, however data is stored in a single AZ, still 11x9s durability, but only 99.5% availability. **Cost is 20% less** than regular S3 IA
    - **Reduced Redudancy Storage**: designed to provide 99.99% durability and 99.99% availability. Used for **data that can be recreated if lost**, e.g. thumbnails
        - Fading out, but might still appear on the exam
    - **Glacier**: very cheap, but used for **archival only**. Optimised for data that is infrequently accessed, takes 3-5 hours to restore
- **Intelligent Tiering**
    - Recommended for unknown or unpredictable access patterns
    - 2 tiers, frequent and infrequent access
    - Automatically moves your data to most cost-effective tier based on how frequently you access each object
    - Objects are moved to infrequent access tier after not being accessed for 30 or more days, and moved to frequent access as soon as it is accessed again
    - No fees for accessing data, but small monthly fee for monitoring and automation, based on number of objects
- You are charged for:
    - Storage per GB
    - Requests (get, put, copy, etc)
    - Storage management pricing (inventory, analytics, object tags)
    - Data management pricing: data transferred out of s3
    - Transfer acceleration: use of CloudFront to optimize transfers

## Security
- By default, all newly created buckets are **private** (only the owner of the bucket has access to it and its contents)
- You can set up access control to your buckets using:
    - **Bucket policies**: applied at a bucket level, json file
    - **Access Control Lists**: applied at an object level
- Buckets can be configured to create **access logs**, which logs all requests made to the bucket. These logs can be written to another bucket